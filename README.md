# torch-BlazefaceDistillation


# Abstract
This is Distillation for Converting performance of [MobileNet backborn BlazeFace(google)](https://google.github.io/mediapipe/solutions/face_detection.html) to ResNet backborn BlazeFace(original).

Use KL divergence loss and softmax with temperature.

<img src="https://user-images.githubusercontent.com/48679574/122851087-5bbb3180-d349-11eb-8cda-82ff78a8efb4.png" width="700px">





# Distillation perfomance (Resnet backborn BlazeFace)

<b>1.MobileNet-backborn.(left)   Resnet-backborn(right)</b>





<b>2.MobileNet-backborn.(left)   Resnet-backborn(right)</b>


# training log 


